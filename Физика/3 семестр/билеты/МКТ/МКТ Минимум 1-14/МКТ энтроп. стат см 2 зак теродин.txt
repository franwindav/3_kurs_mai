Энтропия. Статистический смысл второго закона термодинамики.

В статистической физике энтропия является мерой вероятности осуществления какого-либо макроскопического состояния.
Изолированная система, первоначально находившаяся в состоянии, характеризуемом малой вероятностью, будет стремиться к состоянию, характеризуемому большей вероятностью. Следовательно, энтропия изолированной системы не может убывать.

треугольник S>=0

Энтропия системы, как и внутренняя энергия, является функцией состояния, и ее можно выразить через термодинамические характеристики. Так, если в системе протекают только обратимые процессы, то:
dS=бQ/T
Если необратимые:
dS>бQ/T

Cтатистический смысл:
Второй закон термодинамики указывает на отличие необратимых процессов от обратимых.
а) Необратимые процессы менее экономны, чем обратимые, то есть при необратимом процессе остается некоторая часть тепла, не превращённая в механическую работу.
б) С более общей точки зрения процесс А->В обратим или необратим не из-за того, что выбран тот или иной способ перехода от одного состояния к другому, а от свойств самих состояний А и В.
в) Вероятность, соответствующая термодинамическому состоянию двух независимых друг от друга систем, равна произведению вероятностей состояния каждой из них в отдельности
W=W1*W2
а энтропия системы выражается суммой отдельных энтропий. Поэтому энтропия пропорциональна логарифму вероятности:
S=k*lnW
